{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\transformers-pytorch\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tokenizers\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"dair-ai/emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'im grabbing a minute to post i feel greedy wrong',\n",
       "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
       "  'i am feeling grouchy'],\n",
       " 'label': [0, 0, 3, 2, 3]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_encoder = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_encoder.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(x):\n",
    "    text = str(x['text'])\n",
    "    num_classes = 5\n",
    "    max_seq_len = 36\n",
    "    \n",
    "    output = token_encoder.encode(text)\n",
    "    output = output if len(output) <= max_seq_len else output[:max_seq_len]\n",
    "    \n",
    "    padding_length = max_seq_len - len(output)\n",
    "    if padding_length > 0:\n",
    "        output += [0] * padding_length\n",
    "    \n",
    "    label = [0 for _ in range(num_classes)]\n",
    "    label[x['label']-1] = 1\n",
    "    \n",
    "    result = {\n",
    "        'text': text,\n",
    "        'encoded_text': output,\n",
    "        'label': label\n",
    "    }\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset_train = dataset['train'].map(encode_text)\n",
    "tokenized_dataset_test = dataset['test'].map(encode_text)\n",
    "tokenized_dataset_validation = dataset['validation'].map(encode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset_train[8]['encoded_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_dataset_train, batch_size=512, shuffle=True)\n",
    "test_dataloader = DataLoader(tokenized_dataset_test, shuffle=True)\n",
    "val_dataloader = DataLoader(tokenized_dataset_validation, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.transformers import EncoderClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "max_seq_len = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"num_layers\": 4,\n",
    "    \"vocab_size\": token_encoder.n_vocab,\n",
    "    \"embed_dims\": 768,\n",
    "    \"max_seq_len\": max_seq_len,\n",
    "    \"n_segments\": 5,\n",
    "    \"heads\": 8,\n",
    "    \"dropout\": 0.3,\n",
    "    \"device\": \"cpu\",\n",
    "    \"ff_layer_sizes\": [768, 256, 768],\n",
    "    \"batch_size\": 512,\n",
    "    \"num_classes\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderClassifier(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_file = \"./models/model_epoch_62.pth\"\n",
    "# model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "# em = token_encoder.encode(\"i feel low energy i m just thirsty\")\n",
    "# n = 36 - len(em)\n",
    "# inp = torch.Tensor(em + [0 for _ in range(n)]).int()\n",
    "# inp = inp.reshape((36,1))\n",
    "\n",
    "# o = model(inp)\n",
    "# o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 29 09:19:36 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 527.41       Driver Version: 527.41       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   72C    P8     3W /  N/A |   3936MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     12968      C   ...s-pytorch\\venv\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "from torch.optim import Adam\n",
    "\n",
    "optim = Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "step = 0\n",
    "device = config['device']\n",
    "acc_list = []\n",
    "loss_list = []\n",
    "val_acc_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training Loop\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for batch in tqdm(train_dataloader, leave=True, desc=f\"Epoch {epoch}:\"):\n",
    "        step+=1\n",
    "        optim.zero_grad()\n",
    "        inputs = torch.stack(batch['encoded_text']).int().to(device)\n",
    "        labels = torch.stack(batch['label']).float()\n",
    "        labels = torch.Tensor(labels).to(device)\n",
    "        labels = labels.transpose(0, 1)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, labels = torch.max(labels, 1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    accuracy = correct_predictions / len(train_dataloader)\n",
    "    acc_list.append(accuracy)\n",
    "    loss_list.append(average_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {average_loss:.4f}, Training Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct_val_predictions = 0\n",
    "\n",
    "    for val_batch in tqdm(val_dataloader, leave=True):\n",
    "        val_inputs = torch.stack(val_batch['encoded_text']).int().to(device)\n",
    "        val_labels = torch.stack(val_batch['label']).float()\n",
    "        val_labels = torch.Tensor(val_labels).to(device)\n",
    "        val_labels = val_labels.transpose(0, 1)\n",
    "\n",
    "        val_outputs = model(val_inputs)\n",
    "        val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "        total_val_loss += val_loss.item()\n",
    "        _, val_labels = torch.max(val_labels, 1)\n",
    "        _, val_predicted = torch.max(val_outputs, 1)\n",
    "        correct_val_predictions += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    average_val_loss = total_val_loss / len(val_dataloader)\n",
    "    val_accuracy = correct_val_predictions / len(val_dataloader)\n",
    "    val_acc_list.append(val_accuracy)\n",
    "    val_loss_list.append(average_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Save the model after each epoch if needed\n",
    "    # torch.save(model.state_dict(), f'models/model_epoch_{epoch + 1}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
